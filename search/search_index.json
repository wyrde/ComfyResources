{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"README","text":""},{"location":"#readme-for-comfyui-resources","title":"README for ComfyUI Resources","text":"<ul> <li>web: https://wyrde.github.io/ComfyResources/ (this page)</li> <li>web1: </li> <li>repo: https://github.com/wyrde/ComfyResources</li> </ul>"},{"location":"#node-list","title":"Node List","text":"<ul> <li>Click <code>Nodes</code> above or click here for the wiki.</li> <li>Click here for the repo.</li> </ul>"},{"location":"#purpose","title":"Purpose","text":"<ul> <li>This is a simple copy of the ComfyUI resources pages on Civitai.com</li> <li>It is meant to be an quick source of links and is not comprehensive or complete. Only the top page of each listing is here.</li> <li>If you are the owner of a resource and want it removed, do a local fork removing it on github and a PR. (This is the easiest way to authenticate ownership.)</li> <li>Links to resources and sources other than those hosted by civit are okay! </li> <li>If you're the owner of a resource and want to improve the listing, add links, or even an archive, open PRs with the changes. Though in most cases I'd much rather a link to github, huggingfaces, or other repo be provided rather than releases. If you desire images/archives included in a listing, please create a subdirectory and place everything in there to keep the main area tidy.</li> <li>example:</li> </ul> <pre><code>    nodename\\\n             readme.md\n             node.py\n             node.zip\n             node.png\n</code></pre> <ul> <li>If you know of a resource missing from here, ask the author to open a PR adding it (or permission to do so)! That'd be awesome. (:</li> </ul>"},{"location":"#md-fille-format","title":"md fille format","text":"<p>This page can be used as a template.</p> <pre><code>filename\n========================\n\n# full project name\n\n* web: URL for project website (usually civitai)\n* web1: alternate URL. For each additional, add a number\n* repo: git-or other cvs system-enabled repository\n\nmain body: the rest is project text with no standard format\n</code></pre> <ul> <li>The file name is also a short name for the project. In most caes, \"Comfy\" or \"ComfyUI\" can be left off since, logically, that's what all the files in this repo are for.</li> <li>The blank lines are important for formatting</li> <li>The <code>*</code> are for generating a list</li> <li>websites are places the nodes/files can be downloaded</li> <li>social media and other links should go in the main body</li> </ul>"},{"location":"#special-mention","title":"Special Mention","text":"<ul> <li>ltdrdata's Comfy Manager</li> <li>help organize and install various custom nodes</li> </ul> <p>happy nodes,</p> <p>--wyn</p>"},{"location":"nodes/","title":"Index","text":""},{"location":"nodes/#node-index","title":"Node Index","text":"<p>\u2190 There should be a list of nodes to the left.</p>"},{"location":"nodes/#installing","title":"Installing","text":"<ul> <li>Most include installation instructions on their civit and/or repo pages.</li> <li>ltdrdata's Comfy Manager can streamline the process for many nodes.</li> <li>general instructions for installing custom nodes</li> </ul>"},{"location":"nodes/Allor%20Plugin/","title":"Allor Plugin","text":""},{"location":"nodes/Allor%20Plugin/#comfyui-allor-plugin","title":"ComfyUI Allor Plugin","text":"<ul> <li>web: </li> <li>repo: https://github.com/Nourepide/ComfyUI-Allore</li> </ul>"},{"location":"nodes/Allor%20Plugin/#about-allor","title":"About Allor:","text":"<p>Allure is a plugin for ComfyUI with an emphasis on transparency and performance.</p> <ul> <li>All modules support transparency, multi-image and are easy to use.</li> <li>One of the main features is the ability to combine several images of different sizes.</li> <li>Almost all functionality is implemented in tensor space without transformation into an image, where possible. This allows you to achieve an incredible speed of work, in some places the speed increases from 1-2 seconds to 4-6 milliseconds.</li> </ul>"},{"location":"nodes/CLIP%20BLIP%20Node/","title":"CLIP BLIP Node","text":""},{"location":"nodes/CLIP%20BLIP%20Node/#comfyui-clip-blip-node","title":"ComfyUI CLIP BLIP Node","text":"<ul> <li>web: https://civitai.com/models/42974/comfyui-clip-blip-node</li> <li>repo: </li> </ul> <p>CLIPTextEncode Node with BLIP Dependencies</p> <pre><code>Fairscale&gt;=0.4.4 (NOT in ComfyUI)\n\nTransformers==4.26.1 (already in ComfyUI)\n\nTimm&gt;=0.4.12 (already in ComfyUI)\n\nGitpython (already in ComfyUI)\n</code></pre> <p>Local Installation</p> <p>Inside ComfyUI_windows_portable\\python_embeded, run:</p> <pre><code>python.exe -m pip install fairscale\n</code></pre> <p>And, inside ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\, run:</p> <pre><code>git clone https://github.com/paulo-coronado/comfy_clip_blip_node\n</code></pre> <p>Google Colab Installation</p> <p>Add a cell anywhere, with the following code:</p> <pre><code>!pip install fairscale\n!cd custom_nodes &amp;&amp; git clone https://github.com/paulo-coronado/comfy_clip_blip_node\n</code></pre> <p>How to use</p> <ul> <li>Add the CLIPTextEncodeBLIP node;</li> <li>Connect the node with an image and select a value for min_length and max_length;</li> <li>Optional: if you want to embed the BLIP text in a prompt, use the keyword BLIP_TEXT (e.g. \"a photo of BLIP_TEXT\", medium shot, intricate details, highly detailed).</li> </ul> <p>Acknowledgement * The implementation of CLIPTextEncodeBLIP relies on resources from BLIP, ALBEF, Huggingface Transformers, and timm. We thank the original authors for their open-sourcing.</p> <p> </p> <p>https://civitai.com/user/PauloCoronado y Use the model without crediting the creator n Sell images they generate n Run on services that generate images for money y Share merges using this model n Sell this model or merges using this model y Have different permissions when sharing merges</p>"},{"location":"nodes/ComfyBox/","title":"ComfyBox","text":""},{"location":"nodes/ComfyBox/#comfybox-frontent","title":"ComfyBox Frontent","text":"<ul> <li>web: </li> <li>repoi: https://github.com/space-nuko/ComfyBox</li> </ul> <p>ComfyBox is a frontend to Stable Diffusion that lets you create custom image generation interfaces without any code. It uses ComfyUI under the hood for maximum power and extensibility.</p>"},{"location":"nodes/ComfyUI%20Colab/","title":"ComfyUI Colab","text":""},{"location":"nodes/ComfyUI%20Colab/#comfyui-colab_1","title":"ComfyUI Colab","text":"<ul> <li>web: https://civitai.com/models/25284/comfyui-colab</li> <li>repo: https://github.com/camenduru/comfyui-colab</li> </ul> <p>\ud83d\udc23 Please follow me for new updates https://twitter.com/camenduru \ud83d\udd25 Please join our discord server https://discord.gg/k5BwmmvJJU</p> <p>https://civitai.com/user/camenduru</p>"},{"location":"nodes/ComfyUI%20Manager/","title":"ComfyUI Manager","text":""},{"location":"nodes/ComfyUI%20Manager/#comfyui-manager_1","title":"ComfyUI Manager","text":"<ul> <li>web: </li> <li>repo: https://github.com/ltdrdata/ComfyUI-Manager</li> </ul> <p>A manager for custom nodes/extensions. Installed as a node and operates in ComfyUI.</p> <p>Installation: https://github.com/ltdrdata/ComfyUI-Manager#installation</p> <p>Expanded install instructions https://github.com/wyrde/wyrde-comfyui-workflows/tree/main/basics/building-up#using-the-comfyui-manager</p>"},{"location":"nodes/CushyNodes/","title":"CushyNodes","text":""},{"location":"nodes/CushyNodes/#cushynodes_1","title":"CushyNodes","text":"<ul> <li>web:</li> <li>repo: https://github.com/rvion/CushyNodes</li> </ul> <p>ComfyUI Nodes and APIs intended to be used with CushyStudio. If using without CushyStudio, you might want to deactivate the additional API paths. To do this, just change activate_apis = True to activate_apis = False in init.py</p> <p>See also: CushyStudio</p>"},{"location":"nodes/CushyStudio/","title":"CushyStudio","text":""},{"location":"nodes/CushyStudio/#cushystudio-generative-art-studio","title":"CushyStudio - Generative Art studio","text":"<ul> <li>web: </li> <li>repo: https://github.com/rvion/CushyStudio</li> </ul> <p>CushyStudio is an AI-powered Generative-Art studio for creatives and developpers, enabling new ways to produce art, assets, or animations. It offers scripting tools and dynamic interfaces for live human-feedback, curation and guidance along generation processes. It is cross-platform and open-source.</p> <p>Requires a ComfyUI setup available.</p> <p>See also: CushyNodes</p>"},{"location":"nodes/Custom%20Nodes%20Extensions%20and%20Tools%20List/","title":"Custom Nodes Extensions and Tools List","text":""},{"location":"nodes/Custom%20Nodes%20Extensions%20and%20Tools%20List/#custom-nodes-extensions-and-tools-for-comfyui","title":"Custom Nodes, Extensions, and Tools for ComfyUI","text":"<ul> <li>web:</li> <li>repo: https://github.com/WASasquatch/comfyui-plugins</li> </ul> <p>An alternative list of nodes and resources</p>"},{"location":"nodes/Custom%20Nodes%20by%20xss/","title":"Custom Nodes by xss","text":""},{"location":"nodes/Custom%20Nodes%20by%20xss/#comfyui-custom-nodes-by-xss","title":"ComfyUI Custom Nodes by xss","text":"<ul> <li>web: https://civitai.com/models/24869/comfyui-custom-nodes-by-xss</li> <li>repo: </li> </ul> <p>Custom Nodes for ComfyUI</p> <p>These are a collection of nodes I have made to help me in my workflows. None of the nodes here require any external dependencies or packages that aren't part of the base ComfyUI install so they should be plug and play.</p> <p>Installation</p> <pre><code>Download the node's .zip file\n\nExtract it into your ComfyUI\\custom_nodes folder\n\nRestart your ComfyUI server instance\n\nRefresh the browse you are using for ComfyUI\n\nHave fun!\n</code></pre> <p>https://civitai.com/user/xss This model permits users to:</p> <p>y Use the model without crediting the creator y Sell images they generate n Run on services that generate images for money y Share merges using this model n Sell this model or merges using this model y Have different permissions when sharing merges</p>"},{"location":"nodes/Cutoff%20for%20ComfyUI/","title":"Cutoff for ComfyUI","text":""},{"location":"nodes/Cutoff%20for%20ComfyUI/#cutoff-for-comfyui_1","title":"Cutoff for ComfyUI","text":"<ul> <li>web: https://civitai.com/models/28295/cutoff-for-comfyui</li> <li>repo: https://github.com/BlenderNeko/ComfyUI_Cutoff</li> </ul> <p>This is a node based implementation of the cutoff extension for A1111. Cutoff is a method to limit the influence of specific tokens to certain regions of the prompt. This can be helpful if you want to e.g. specify exactly what colors certain things in the generated image should be.</p> <p>For a detailed explanation of the method, the introduced nodes, or raise an issue, please see the github page for this project. You can take any of the example images listed in the gallery and load them into ComfyUI to have a closer look at an example node tree.</p> <p>To install simply unzip into the custom_nodes folder.</p> <p>https://civitai.com/user/nekomata</p>"},{"location":"nodes/Derfuu%20Math%20and%20Modded%20Nodes/","title":"Derfuu Math and Modded Nodes","text":""},{"location":"nodes/Derfuu%20Math%20and%20Modded%20Nodes/#comfyui-derfuu-math-and-modded-nodes","title":"ComfyUI Derfuu Math and Modded Nodes","text":"<ul> <li>web: https://civitai.com/models/21558/</li> <li>repo: https://github.com/Derfuu/Derfuu_ComfyUI_ModdedNodes#nodes-descriptions</li> </ul> <p>ComfyUI: https://github.com/comfyanonymous/ComfyUI</p> <p>Github repo + nodes description: https://github.com/Derfuu/Derfuu_ComfyUI_ModdedNodes#nodes-descriptions</p> <p>Leave suggestions and errors if you meet them</p> <p>What's new in 0.5.0:</p> <pre><code>CombiningArea scaler\n\nMore user-friendly ui names\n\nALL nodes description moved to https://github.com/Derfuu/Derfuu_ComfyUI_ModdedNodes#nodes-descriptions\n\nTuples and so on moved to their own directory in UI\n</code></pre> <p>Simple* introduction:</p> <pre><code>Automate calculation depending on image sizes or something you want\n\neasier(or not) editing multiple values of various nodes\n\nMath\n\nModded scalers\n</code></pre> <p>Installing: unzip files in ComfyUI/custom_nodes folder</p> <p>Should look like this:</p> <p>For example (v0.5.0) there is an example how scaled ConditioningArea can improve image after scaled latent combining:</p> <p>Only LatentCombine:</p> <p>Combining preview:</p> <p>LatentCombine with scaled ConditioningArea (640360 to 1360768):</p> <p>Example of workflow i made for this located in: /Derfuu_ComfyUI_ModdedNodes/workflow_examples/</p> <p>model: hPANTYHOSENEKO (sorry, couldn't find link)</p> <p>negative promp: embedding:verybadimagenegative6400</p> <p>TROUBLESHOOTING:</p> <p>If there are troubles with different sizes, aside from *64, this may solve problem: found on GitHUB</p> <p>This code is at the end of this file: /ComfyUI/comfy/ldm/modules/diffusionmodules/openaimodules.py</p> <p>NOTES#2:</p> <p>Debug nodes counts as OUTPUT nodes and can be used withowt image preview or save nodes to get results</p> <p>P.S.:</p> <p>All fixes wou can find or post on github, i look there too</p> <p>If you catch error like: Calculated padded input size per channel: (2 x 82). Kernel size: (3 x 3). Kernel size can't be greater than actual input size. This MAY be because of too high or low offset you give to node</p> <p>https://civitai.com/user/Derfuu This model permits users to: y Use the model without crediting the creator y Sell images they generate y Run on services that generate images for money y Share merges using this model n Sell this model or merges using this model y Have different permissions when sharing merges</p>"},{"location":"nodes/Efficiency%20Nodes%20for%20ComfyU/","title":"Efficiency Nodes for ComfyU","text":""},{"location":"nodes/Efficiency%20Nodes%20for%20ComfyU/#efficiency-nodes-for-comfyu_1","title":"Efficiency Nodes for ComfyU","text":"<ul> <li>web: https://civitai.com/models/32342/efficiency-nodes-for-comfyui</li> <li>repo: https://github.com/LucianoCirino/efficiency-nodes-comfyui</li> </ul> <p>A collection of ComfyUI custom nodes to help streamline workflows and reduce total node count.</p> <p>Github Repo: https://github.com/LucianoCirino/efficiency-nodes-comfyui</p> <p>Currently Available Nodes:</p> <p>Ksampler (Efficient)</p> <pre><code>A modded KSampler with the ability to preview and output images.\n\nRe-outputs key inputs which helps promote a cleaner and more streamlined workflow look for ComfyUI.\n\nCan force hold all of its outputs without regenerating by setting its state to \"Hold\".\n</code></pre> <p>note: when using multiple instances of this node, each instance must have a unique ID for the \"Hold\" state to function properly.</p> <p>Efficient Loader</p> <pre><code>A combination of common initialization nodes.\n</code></pre> <p>Image Overlay</p> <pre><code>Node that allows for flexible image overlaying.\n</code></pre> <p>Evaluate Integers</p> <pre><code>3 integer input node that gives the user ability to write their own python expression for a INT/FLOAT type output.\n</code></pre> <p>Evaluate Strings</p> <pre><code>3 string input node that\n</code></pre> <p>https://civitai.com/user/luciano.a.cirino488</p>"},{"location":"nodes/FaceRestore%20Node/","title":"FaceRestore Node","text":""},{"location":"nodes/FaceRestore%20Node/#comfyui-facerestore-node","title":"ComfyUI - FaceRestore Node","text":"<ul> <li>web: https://civitai.com/models/24690/</li> <li>repo:</li> </ul> <p>FaceRestore node for ComfyUI. To install copy the facerestore directory from the zip to the custom_nodes directory in ComfyUI.</p> <p>I bodged this together in an afternoon. You might need to pip install a package if it doesn't work at first.</p> <p>You'll need codeformer-v0.1.0.pth or GFPGANv1.4.pth in your models/upscale_models directory. The node uses another model for face detection which it will download and put in models/facedetection</p> <p>https://civitai.com/user/m99</p>"},{"location":"nodes/GPT%20node%20ComfyUI/","title":"GPT node ComfyUI","text":""},{"location":"nodes/GPT%20node%20ComfyUI/#gpt-node-comfyui_1","title":"GPT node ComfyUI","text":"<ul> <li>web: https://civitai.com/models/31696/gpt-node-comfyui</li> <li>repo:</li> </ul> <p>Waiting to be supplemented, comfyUI nodes built around openai and gpt</p> <p>https://civitai.com/user/Isle_of_Chaos</p>"},{"location":"nodes/Image%20Processing/","title":"Image Processing","text":""},{"location":"nodes/Image%20Processing/#bvhars-comfyui_imageprocessing","title":"bvhar's ComfyUI_ImageProcessing","text":"<ul> <li>web:</li> <li>repo: https://github.com/bvhari/ComfyUI_ImageProcessing</li> </ul> <p>ComfyUI custom nodes to apply various image processing techniques</p> <p>Uses Kornia https://kornia.readthedocs.io/en/latest/index.html</p> <p>https://github.com/bvhari</p>"},{"location":"nodes/ImagesGrid%20X-Y%20Plot/","title":"ImagesGrid X-Y Plot","text":""},{"location":"nodes/ImagesGrid%20X-Y%20Plot/#imagesgrid-comfy-plugin-xy-plot","title":"ImagesGrid: Comfy plugin (X/Y Plot)","text":"<ul> <li>web: https://civitai.com/models/31126/imagesgrid-comfy-plugin-xy-plot</li> <li>repo:  https://github.com/LEv145/images-grid-comfy-plugin</li> </ul> <p>ImagesGrid (X/Y Plot): Comfy plugin</p> <p>A simple ComfyUI plugin for images grid (X/Y Plot) Preview Simple grid of images Image XYZPlot, like in auto1111, but with more settings Image</p> <p>Workflows: https://github.com/LEv145/images-grid-comfy-plugin/tree/main/workflows How to use</p> <p>Download the latest stable release: https://github.com/LEv145/images-grid-comfy-plugin/archive/refs/heads/main.zip</p> <p>Unpack the node to custom_nodes, for example in a folder custom_nodes/ImagesGrid/</p> <p>https://civitai.com/user/LEv145_</p>"},{"location":"nodes/Impact%20Pack/","title":"Impact Pack","text":""},{"location":"nodes/Impact%20Pack/#comfyui-impact-pack","title":"ComfyUI Impact Pack","text":"<ul> <li>web: https://civitai.com/models/33192/comfyui-impact-pack</li> <li>repo: https://github.com/ltdrdata/ComfyUI-Impact-Pack</li> </ul> <p>This custom node pack provides various model-based detection nodes and a detailer node that recreates mask areas in high resolution. It also offers simple inpainting assistant functions such as a mask editor.</p> <p>Please refer to the GitHub page for more detailed information.</p> <p>https://github.com/ltdrdata/ComfyUI-Impact-Pack</p> <p>Install guide:</p> <pre><code>Download\n\nUncompress into ComfyUI/custom_nodes\n\nRestart ComfyUI\n</code></pre> <p>Troubleshootings:</p> <pre><code>Occasionally, when a new parameter is created in an update, the values of nodes created in the previous version can be shifted to different fields. This can result in unintended results or errors if executed as is, so it is important to check the node values. In particular, when updating from version v1.4 or earlier to version v1.5, all parameter values under guide_size will be different, so be careful when using previously created workflows.\n</code></pre> <p>https://civitai.com/user/DrLtData</p>"},{"location":"nodes/Latent%20To%20RGB/","title":"Latent To RGB","text":""},{"location":"nodes/Latent%20To%20RGB/#bvhars-comfyui_latenttorgb","title":"bvhar's ComfyUI_LatentToRGB","text":"<ul> <li>web:</li> <li>repo: https://github.com/bvhari/ComfyUI_LatentToRGB</li> </ul> <p>ComfyUI custom node to convert latent to RGB</p> <p>Transformation matrix taken from here: https://discuss.huggingface.co/t/decoding-latents-to-rgb-without-upscaling/23204/2</p> <p>https://github.com/bvhari</p>"},{"location":"nodes/Loopback%20nodes/","title":"Loopback nodes","text":""},{"location":"nodes/Loopback%20nodes/#comfyui-loopback-nodes","title":"ComfyUI - Loopback nodes","text":"<ul> <li>web: https://civitai.com/models/26836/comfyui-loopback-nodes</li> <li>repo:</li> </ul> <p>Loop the output of one generation into the next generation.</p> <p>To use create a start node, an end node, and a loop node. The loop node should connect to exactly one start and one end node of the same type. The first_loop input is only used on the first run. Whatever was sent to the end node will be what the start node emits on the next run.</p> <p>More loop types can be added by modifying loopback.py</p> <p>https://civitai.com/user/m99</p>"},{"location":"nodes/Masquerade%20Nodes/","title":"Masquerade Nodes","text":""},{"location":"nodes/Masquerade%20Nodes/#masquerade-nodes-comfyui","title":"Masquerade Nodes - ComfyUI","text":"<ul> <li>web: https://civitai.com/models/52723/masquerade-nodes-comfyui</li> <li>repo: https://github.com/BadCafeCode/masquerade-nodes-comfyui</li> </ul> <p>This is a node pack for ComfyUI, primarily dealing with masks.</p> <p>Notably, it contains a \"Mask by Text\" node that allows dynamic creation of a mask from a text prompt.</p> <p>See full node documentation at https://github.com/BadCafeCode/masquerade-nodes-comfyui</p> <p>Some example workflows this pack enables are:</p> <pre><code>Fine control over composition via automatic photobashing (see examples/composition-by-photobashing.json)\n\nInpaint all faces at a higher resolution (see examples/inpaint-faces.json)\n\nInpaint all buildings with a particular LORA (see examples/inpaint-with-lora.json)\n\nFiltering out images/change save location of images that contain certain objects/concepts without the side-effects caused by placing those concepts in a negative prompt (see examples/filter-by-season.json)\n</code></pre> <p>Note that you may have to update ComfyUI to be able to inpaint with more than one mask at a time.</p> <p>https://civitai.com/user/BadCafeCode This model permits users to: n Use the model without crediting the creator y Sell images they generate y Run on services that generate images for money n Share merges using this model n Sell this model or merges using this model y Have different permissions when sharing merges</p>"},{"location":"nodes/Multiple%20Subject%20Workflows/","title":"Multiple Subject Workflows","text":""},{"location":"nodes/Multiple%20Subject%20Workflows/#multiple-subject-workflows_1","title":"Multiple Subject Workflows","text":"<ul> <li>web: https://civitai.com/models/21100/</li> <li>repo: </li> </ul> <p>This is a collection of custom workflows for ComfyUI</p> <p>They can generate multiple subjects. Each subject has its own prompt.</p> <p>They require some custom nodes to function properly, mostly to automate out or simplify some of the tediousness that comes with setting up these things. You can find the requirements listed in each download's description</p> <p>There are three methods for multiple subjects included so far: Latent Couple</p> <p>Limits the areas affected by each prompt to just a portion of the image</p> <p>Includes ControlNet and unCLIP (enabled by switching node connections)</p> <p>From my testing, this generally does better than Noisy Latent Composition</p> <p>Noisy Latent Composition</p> <p>Generates each prompt on a separate image for a few steps (eg. 4/20) so that only rough outlines of major elements get created, then combines them together and does the remaining steps with Latent Couple Character Interaction</p> <p>This is an \"\"\"attempt\"\"\" at generating 2 characters interacting with each other, while retaining a high degree of control over their looks, without using ControlNets. As you may expect, it's quite unreliable.</p> <p>We do this by generating the first few steps (eg. 6/30) on a single prompt encompassing the whole image that describes what sort of interaction we want to achieve (+background and perspective, common features of both characters help too).</p> <p>Then, for the remaining steps in the second KSampler, we add two more prompts, one for each character, limited to the area where we \"expect\" (guess) they'll appear, so mostly just the left half/right half of the image with some overlap.</p> <p>I'm not gonna lie, the results and consistency aren't great. If you want to try it, some settings to fiddle around with would be at which step the KSampler should change, the amount of overlap between character prompts and prompt strengths. From my testing, the closest interaction I've been able to get out of this was a kiss, I've tried to go for a hug but with no luck.</p> <p>The higher the step that you switch KSamplers at, the more consistently you'll get the desired interaction, but you'll lose out on the character prompts (I've been going between 20-35% of total steps). You may be able to offset this a bit by increasing character prompt strengths</p> <p>https://civitai.com/user/Bocian</p>"},{"location":"nodes/Node%20setup%20-%20LoRA%20Stack/","title":"Node setup - LoRA Stack","text":""},{"location":"nodes/Node%20setup%20-%20LoRA%20Stack/#comfyui-node-setup-lora-stack","title":"ComfyUI Node setup - LoRA Stack","text":"<ul> <li>web: https://civitai.com/models/50440/comfyui-node-setup-lora-stack</li> <li>repo: </li> </ul> <p>To create node template for LoRA Stacking with key word input</p> <p>I am still testing this</p> <p>Mixing LoRA sometimes is more a game of guessing compatibility, so experiment around with it and don't expect best results right away.</p> <p>https://civitai.com/user/CyberSnacc</p>"},{"location":"nodes/NodeGPT/","title":"NodeGPT","text":""},{"location":"nodes/NodeGPT/#nodegpt_1","title":"NodeGPT","text":"<ul> <li>web: https://civitai.com/models/33905/nodegpt</li> <li>repo: https://github.com/xXAdonesXx/NodeGPT</li> </ul> <p>ComfyUI Extension Nodes for Automated Text Generation.</p> <p>https://github.com/xXAdonesXx/NodeGPT</p> <p>https://civitai.com/user/Antonym</p>"},{"location":"nodes/Prompt%20weighting%20interpretations%20for%20ComfyUI/","title":"Prompt weighting interpretations for ComfyUI","text":""},{"location":"nodes/Prompt%20weighting%20interpretations%20for%20ComfyUI/#prompt-weighting-interpretations-for-comfyui_1","title":"Prompt weighting interpretations for ComfyUI","text":"<ul> <li>web: https://civitai.com/models/46229</li> <li>repo: https://github.com/BlenderNeko/ComfyUI_ADV_CLIP_emb</li> </ul> <p>Contains a node that lets you set how ComfyUI should interpret up/down-weighted tokens. By default ComfyUI does not interpret prompt weighting the same way as A1111 does. This node lets you switch between different ways in which this is done in frameworks such as ComfyUI, A1111 and compel. It also includes a node that let's you mix CLIP embeddings for some additional customization.</p> <p>For a detailed explanation of the methods, the introduced nodes, or raise an issue, please see the github page for this project.</p> <p></p> <p>https://civitai.com/user/nekomata</p>"},{"location":"nodes/Quality%20of%20life%20Suit%20V2/","title":"Quality of life Suit V2","text":""},{"location":"nodes/Quality%20of%20life%20Suit%20V2/#comfyui-quality-of-life-suitv2-auto-updatechat-gpt-dalle-2-math-and-more","title":"ComfyUI \"Quality of life Suit:V2\" (auto Update,Chat GPT , DallE-2 ,Math, ... and more )","text":"<ul> <li>web: https://civitai.com/models/21996</li> <li>repo: https://github.com/omar92</li> </ul> <p>If you like my work Kindly like,rate and comment XD</p> <p>These nodes are for : ComfyUI ComfyUI:</p> <p>ComfyUI is an advanced node based UI utilizing Stable Diffusion. It allows you to create customized workflows such as image post-processing, or conversions.</p> <p>Auto Update:</p> <p>-when you run comfyUI, the suit will generate a config file</p> <p>The file looks like this : {</p> <p>\"autoUpdate\": true,</p> <p>\"branch\": \"main\",</p> <p>\"openAI_API_Key\": \"sk-#################################\"</p> <p>}</p> <p>this file is used to control Auto update, and to manage any other settings the tool requires</p> <p>File Description: \"autoUpdate\": can be (true) or (false), \"branch\": default is (\"main\")</p> <p>other options for branch:</p> <pre><code>\"v2.1.X\": means it will only update bug fixes for v2 version.\n\n\"main\" means it will always be on latest stable build, this may add new nodes suddenly (also usually it assume you update comfy)\n\n\"develop\": it will contain latest stuff I'm working on now, but may contain bugs\n</code></pre> <p>\"openAI_API_Key\": if you want to use the ChatGPT or Dall-E2 features, you need to add your open-AI API key, you can get it from (Account API Keys - OpenAI API) How to use</p> <pre><code>you must update comfyUI first before using this version\n</code></pre> <p>As this version relies heavily on the new feature of comfyUI : the ability to switch inputs to be widgets and widgets to be inputs</p> <pre><code>Download the zip file.\n\nExtract to ..\\ComfyUI\\custom_nodes : like this image :\n\nrestart comfy if it was running (reload web, not enough)\n\nyou will find my nodes under new group O/\u2026\n\nYou can check the workflow folder to find great examples of how to use the tool\n</code></pre> <p>Kindly be notified that you can load the images in the downloaded ZIP/workflows in comfyUI to load the workflow that was used to generate it</p> <p>Current Nodes:</p> <p>//7/4/2023 -----------------------------------------------------------------</p> <pre><code>selectLatentFromBatchNode\nif you generate multiple images, it allows you to pick which to use\nfor example, if you generate 4 images, it allows you to select 1 of them to do further processing on it\n\nor you can use it to process them sequentially\n\nNSP\nthis node allow you to select random value from SoupPrompts file\n\nequations\n- this node allow you to perform math equations on the input\n- there are two variants\n- 1 input (X)\n- 2 inputs (X,Y)\n(you can convert the x and y to inputs by right click on them, so you can use values from another node)\n\nif you like this node tell me i can enhance it so you can select inputs number\n</code></pre> <p>// 22/3/2023 -----------------------------------------------------------------</p> <p>OpenAI Nodes</p> <p>OpenAI ChatGPT and DALLE-2 API as nodes, so you can use them to enhance your workflow ChatGPT-Advanced</p> <pre><code>Load_openAI\nto initialize openAI for next nodes\n</code></pre> <p>Advanced ChatGPT nodes</p> <pre><code>chat_message :\ncreate a message to send it to chatGPT\n\ncombine_chat_messages:\nused to group messages together before sending them to chatGPT\n\nChat_Completion:\nthe magic node this node will send the messages to ChatGPT and receive response from it , the response will be the output string\n\ndebug_Completion:\nthis to help you check the whole response\n</code></pre> <p>in this workflow, I used ChatGPT to create the prompt,</p> <pre><code>at start, I send 2 messages to ChatGPT\n\nfirst message is to tell ChatGPT how to behave and what is the prompt format that I need from him\n\nin the second message I send what I want in this case young girl dancing (I added young, so her clothes become decent XD don't misunderstand me please )\n\nafter that I feed the messages to the completion node \u201cit is called like that in their API sorry\u201d\n\nand congrats, you have a nice input for your image\n</code></pre> <p>DallE-2 Image nodes</p> <pre><code>create_image:\nused to create and image using DALLE-2 for now only 1 image each time, will update it in next patch to allow multiple images\n\nvariation_image:\nthis node will generate variations similar to the image you send to it\n</code></pre> <p>this is a full workflow where</p> <p>1- use ChatGPT to generate a prompt</p> <p>2- send that prompt to DALLE-2</p> <p>3- give the generated image to Stable Diffusion to paint over it</p> <p>4- use DALLE-2 to create variations from the output</p> <p>ChatGPT-simple</p> <p>This node harnesses the power of chatGPT, an advanced language model that can generate detailed image descriptions from a small input.</p> <pre><code>You need to have OpenAI API key , which you can find at https://beta.openai.com/docs/developer-apis/overview\n\nOnce you have your API key, add it to the api_key.txt file\n</code></pre> <p>I have made it a separate file, so that the API key doesn't get embedded in the generated images.</p> <p> <p>String Suit</p> <p>add multiple nodes to support string manipulation also a tool to generate image from text</p> <pre><code>String:\nnode that can hold string (text)\n\nDebug String\nthis node will write the string on the console\n\nConcat string\nthis node is used to combine two strings together\n\nTrim string\nthis is used to remove any extra spaces at the start or the end of a string\n\nReplace string &amp; replace string advanced\nused to replace part of the text by another part\n\n&gt;&gt;&gt;&gt; String2image &lt;&lt;&lt;&lt;\nthis node will generate an images based on a text, which can be used with controlNet to add text to the image.\n\u2014 the tool support fonts \u201cadd the font you want in fonts folder\u201d\n\u201cIf you load the example image in comfyUI the workflow that generated it will be loaded\u201d\n\n&gt;&gt;&gt;&gt;CLIPStringEncode &lt;&lt;&lt;\nThe normal ClipTextEncode node but this one receive the text from the string node, so you don't have to retype your prompt twice anymore\n</code></pre> <p>in this example I used depth filter but if you are using WAS nodes you can convert the text to canny using WAS canny filter it will give much better results with the canny controlNet</p> <p>Other tools</p> <pre><code>LatentUpscaleMultiply:\nit is a variant from the original LatentUpscale tool but instead of using width and height you use a multiply number\nfor example, if the original images dimensions are (512,512) and the mul values were (2,2) the result image will be (1024,1024)\nalso you can use it to downscale if needed by using fractions ex:(512,512) mul (.5,.5) \u2192 (256,256)\nNode Path: O/Latent/LatentUpscaleMultiply\n</code></pre> <p>there are also many brilliant nodes in this package WAS's Comprehensive Node Suite - ComfyUI | Stable Diffusion Other | Civitai</p> <p>thanks for reading my message, I hope that my tools will help you.</p> <p>Discord: Omar92#3374</p> <p>Githup: omar92 (omar abdelzaher sleam) (github.com)</p> <p>https://civitai.com/user/omar92</p>"},{"location":"nodes/Saveaswebp/","title":"Saveaswebp","text":""},{"location":"nodes/Saveaswebp/#comfyui-saveaswebp","title":"ComfyUI-Saveaswebp","text":"<ul> <li>web: </li> <li>repo: https://github.com/Kaharos94/ComfyUI-Saveaswebp</li> </ul> <p>Save a picture as Webp file in Comfy + Workflow loading</p>"},{"location":"nodes/Saveaswebp/#description","title":"Description:","text":"<p>This adds a custom node to save a picture as a Webp File and also adds a script to Comfy to drag and drop generated webpfiles into the UI to load the workflow.</p> <p>I've added a compression slider and a lossy/lossless option. The compression slider is a bit misleading.</p> <p>In lossless mode, it only affects the \"effort\" taken to compress where 100 is the smallest possible size and 1 is the biggest possible size, it's a tradeoff for saving speed.</p> <p>In lossy mode, that's the other way around, where 100 is the biggest possible size with the least compression and 1 is the smallest possible size with maximum compression.</p> <p>On default it's set to lossy with a compression of 80, below are examples for that.</p>"},{"location":"nodes/Simple%20text%20style%20template%20node/","title":"Simple text style template node","text":""},{"location":"nodes/Simple%20text%20style%20template%20node/#simple-text-style-template-node-for-comfyui","title":"Simple text style template node for ComfyUi","text":"<ul> <li>web: https://civitai.com/models/28238/simple-text-style-template-node-for-comfyui</li> <li>repo:</li> </ul> <p>A node that enables you to mix a text prompt with predefined styles in a styles.csv file. Each line in the file contains a name, positive prompt and a negative prompt. Positive prompts can contain the phrase {prompt} which will be replaced by text specified at run time.</p> <p>https://civitai.com/user/fretts4505</p>"},{"location":"nodes/Super%20Easy%20AI%20Installer%20Tool/","title":"Super Easy AI Installer Tool","text":""},{"location":"nodes/Super%20Easy%20AI%20Installer%20Tool/#super-easy-ai-installer-tool_1","title":"Super Easy AI Installer Tool","text":"<ul> <li>web: https://civitai.com/models/27574/</li> <li>repo: https://github.com/diStyApps/seait</li> </ul> <p>\"Super Easy AI Installer Tool\" is a user-friendly application that simplifies the installation process of AI-related repositories for users. The tool is designed to provide an easy-to-use solution for accessing and installing AI repositories with minimal technical hassle to none the tool will automatically handle the installation process, making it easier for users to access and use AI tools. For Windows 10+ and Nvidia GPU-based cards</p> <p>Don't forget to leave a like/star.</p> <p>For more Info: https://github.com/diStyApps/seait READ BEFORE YOU DOWNLOAD False Positive Virustotal Antivirus Programs.</p> <p>Please note that Virustotal and other antivirus programs may give a false positive when running this app. This is due the use Pyinstaller to convert the python file EXE, which can sometimes trigger false positives even for the simpler scripts which is a known issue</p> <p>Unfortunately, I don't have the time to handle these false positives. However, please rest assured that the code is transparent on https://github.com/diStyApps/seait</p> <p>I would rather add features and more AI tools at this stage of development.</p> <p>Download the \"Super Easy AI Installer Tool\" at your own discretion.</p> <p>Roadmap * Multi-language support * More AI-related repos * Pre installed auto1111 version * Pre installed python version * Locate repo * App updater * Remembering arguments * Adding arguments with input * Maybe arguments profiles * Better event handling</p> <p>https://civitai.com/user/diSty</p>"},{"location":"nodes/Vid2vid%20Node%20Suite/","title":"Vid2vid Node Suite","text":""},{"location":"nodes/Vid2vid%20Node%20Suite/#vid2vid-node-suite-for-comfyui","title":"Vid2vid Node Suite for ComfyUI","text":"<ul> <li>web: https://civitai.com/models/26799/vid2vid-node-suite-for-comfyui</li> <li>repo: https://github.com/sylym/comfy_vid2vid</li> </ul> <p>Vid2vid Node Suite for ComfyUI</p> <p>A node suite for ComfyUI that allows you to load image sequence and generate new image sequence with different styles or content.</p> <p>Refer to Github Repository for installation and usage methods: https://github.com/sylym/comfy_vid2vid</p> <p>https://civitai.com/user/Gomacoma</p>"},{"location":"nodes/Visual%20Area%20Conditioning%20-%20Latent%20composition/","title":"Visual Area Conditioning - Latent composition","text":""},{"location":"nodes/Visual%20Area%20Conditioning%20-%20Latent%20composition/#comfyui-visual-area-conditioning-latent-composition","title":"ComfyUI - Visual Area Conditioning / Latent composition","text":"<ul> <li>web: https://civitai.com/models/24537/</li> <li>repo: https://github.com/Davemane42/ComfyUI_Dave_CustomNode</li> </ul> <p>Davemane42's Custom Node for ComfyUI</p> <p>Also available on Github https://github.com/Davemane42/ComfyUI_Dave_CustomNode</p> <p>Instalation: * Download the .zip archive * extract ComfyUI_Dave_CustomNode folder to ComfyUI/custom_nodes/ * Start ComfyUI * all require file should be downloaded/copied from there. * no need to manually copy/paste .js files anymore</p> <p>MultiAreaConditioning 2.4: * Let you visualize the ConditioningSetArea node for better control * Right click menu to add/remove/swap layers * Display what node is associated with current input selected * Also come with a ConditioningUpscale node. useseful for hires fix workflow</p> <p>MultiLatentComposite 1.1: * Let you visualize the MultiLatentComposite node for better control * Right click menu to add/remove/swap layers * Display what node is associated with current input selected</p> <p>https://civitai.com/user/davemane42</p>"},{"location":"nodes/WASs%20ComfyUI%20Workspaces/","title":"WASs ComfyUI Workspaces","text":""},{"location":"nodes/WASs%20ComfyUI%20Workspaces/#wass-comfyui-workspaces-hr-fix-and-more","title":"WAS's ComfyUI Workspaces (HR-Fix and more!)","text":"<ul> <li>web: https://civitai.com/models/20215/wass-comfyui-workspaces-hr-fix-and-more</li> <li>repo: </li> </ul> <p>These are worksapces to load into ComfyUI for various tasks such as HR-Fix with AI Model Upscaling</p> <p>Note: WAS's Comprehensive Node Suite (WAS Node Suite) has a bloom filter now which works similar, except provides a high frequency pass to base the bloom off of. This is more accurate and used in screen-space bloom like in video games.</p> <p>Requirements:</p> <p>HR-Fix Bloom Workspace depends on Filters Suite V3, and NSP CLIPTextEncode nodes from here: https://civitai.com/models/20793/was-node-suites-comfyui</p> <p>HR-Fix Usage:</p> <ul> <li>Extract \"ComfyUI-HR-Fix_workspace.json\" (or whatever the worksapce is called)</li> <li>Load workspace with the \"Load\" button in the right-hand menu and select \"ComfyUI-HR-Fix_workspace.json\"</li> <li>Select your desired diffusion model</li> <li>Select VAE model or use diffusion models vae</li> <li>Select your desired upscale model</li> <li>change prompt and sampling settings as seen fit.<ul> <li>(currently v1 set to 512x768 x4= 2048x3072, v2 has a resize so final size is 1024x1536)</li> </ul> </li> </ul> <p>https://civitai.com/user/WAS</p>"},{"location":"nodes/WASs%20Comprehensive%20Node%20Suite%20-%20ComfyUI/","title":"WASs Comprehensive Node Suite - ComfyUI","text":""},{"location":"nodes/WASs%20Comprehensive%20Node%20Suite%20-%20ComfyUI/#wass-comprehensive-node-suite-comfyui_1","title":"WAS's Comprehensive Node Suite - ComfyUI","text":"<ul> <li>web: https://civitai.com/models/20793/</li> <li>repo: https://github.com/WASasquatch/was-node-suite-comfyui</li> </ul> <p>WAS's Comprehensive Node Suite - ComfyUI - WAS#0263 https://github.com/WASasquatch/was-node-suite-comfyui</p> <p>ComfyUI is an advanced node based UI utilizing Stable Diffusion. It allows you to create customized workflows such as image post processing, or conversions.</p> <p>Latest Version Download</p> <p>A node suite for ComfyUI with many new nodes, such as image processing, text processing, and more. Share Workflows to the /workflows/ directory. Preferably embedded PNGs with workflows, but JSON is OK too. You can use this tool to add a workflow to a PNG file easily Important Updates</p> <pre><code>ASCII is deprecated. The new preferred method of text node output is TEXT. This is a change from ASCII so that it is more clear what data is being passed.\n\n    The was_suit_config.json will automatically set use_legacy_ascii_text to true for a transition period. You can enable TEXT output by setting use_legacy_ascii_text to false\n</code></pre> <p>Current Nodes:</p> <pre><code>BLIP Analyze Image: Get a text caption from a image, or interrogate the image with a question.\n\n    Model will download automatically from default URL, but you can point the download to another location/caption model in was_suite_config\n\n    Models will be stored in ComfyUI/models/blip/checkpoints/\n\nSAM Model Loader: Load a SAM Segmentation model\n\nSAM Parameters: Define your SAM parameters for segmentation of a image\n\nSAM Parameters Combine: Combine SAM parameters\n\nSAM Image Mask: SAM image masking\n\nImage Bounds: Bounds a image\n\nInset Image Bounds: Inset a image bounds\n\nBounded Image Blend: Blend bounds image\n\nBounded Image Blend with Mask: Blend a bounds image by mask\n\nBounded Image Crop: Crop a bounds image\n\nBounded Image Crop with Mask: Crop a bounds image by mask\n\nCLIPTextEncode (NSP): Parse Noodle Soup Prompts\n\nConstant Number\n\nDictionary to Console: Print a dictionary input to the console\n\nImage Analyze\n\n    Black White Levels\n\n    RGB Levels\n\n        Depends on matplotlib, will attempt to install on first run\n\nImage Blank: Create a blank image in any color\n\nImage Blend by Mask: Blend two images by a mask\n\nImage Blend: Blend two images by opacity\n\nImage Blending Mode: Blend two images by various blending modes\n\nImage Bloom Filter: Apply a high-pass based bloom filter\n\nImage Canny Filter: Apply a canny filter to a image\n\nImage Chromatic Aberration: Apply chromatic aberration lens effect to a image like in sci-fi films, movie theaters, and video games\n\nImage Color Palette\n\n    Generate a color palette based on the input image.\n\n        Depends on scikit-learn, will attempt to install on first run.\n\n    Supports color range of 8-256\n\n    Utilizes font in ./res/ unless unavailable, then it will utilize internal better then nothing font.\n\nImage Dragan Photography Filter: Apply a Andrzej Dragan photography style to a image\n\nImage Edge Detection Filter: Detect edges in a image\n\nImage Film Grain: Apply film grain to a image\n\nImage Filter Adjustments: Apply various image adjustments to a image\n\nImage Flip: Flip a image horizontal, or vertical\n\nImage Gradient Map: Apply a gradient map to a image\n\nImage Generate Gradient: Generate a gradient map with desired stops and colors\n\nImage High Pass Filter: Apply a high frequency pass to the image returning the details\n\nImage History Loader: Load images from history based on the Load Image Batch node. Can define max history in config file. (requires restart to show last sessions files at this time)\n\nImage Levels Adjustment: Adjust the levels of a image\n\nImage Load: Load a image from any path on the system, or a url starting with http\n\nImage Median Filter: Apply a median filter to a image, such as to smooth out details in surfaces\n\nImage Mix RGB Channels: Mix together RGB channels into a single iamge\n\nImage Monitor Effects Filter: Apply various monitor effects to a image\n\n    Digital Distortion\n\n        A digital breakup distortion effect\n\n    Signal Distortion\n\n        A analog signal distortion effect on vertical bands like a CRT monitor\n\n    TV Distortion\n\n        A TV scanline and bleed distortion effect\n\nImage Nova Filter: A image that uses a sinus frequency to break apart a image into RGB frequencies\n\nImage Perlin Noise Filter\n\n    Create perlin noise with pythonperlin module. Trust me, better then my implementations that took minutes...\n\nImage Remove Background (Alpha): Remove the background from a image by threshold and tolerance.\n\nImage Remove Color: Remove a color from a image and replace it with another\n\nImage Resize\n\nImage Rotate: Rotate an image\n\nImage Save: A save image node with format support and path support. (Bug: Doesn't display image\n\nImage Seamless Texture: Create a seamless texture out of a image with optional tiling\n\nImage Select Channel: Select a single channel of an RGB image\n\nImage Select Color: Return the select image only on a black canvas\n\nImage Shadows and Highlights: Adjust the shadows and highlights of an image\n\nImage Size to Number: Get the width and height of an input image to use with Number nodes.\n\nImage Stitch: Stitch images together on different sides with optional feathering blending between them.\n\nImage Style Filter: Style a image with Pilgram instragram-like filters\n\n    Depends on pilgram module\n\nImage Threshold: Return the desired threshold range of a image\n\nImage Transpose\n\nImage fDOF Filter: Apply a fake depth of field effect to an image\n\nImage to Latent Mask: Convert a image into a latent mask\n\nImage Voronoi Noise Filter\n\n    A custom implementation of the worley voronoi noise diagram\n\nInput Switch (Disable until * wildcard fix)\n\nKSampler (WAS): A sampler that accepts a seed as a node inpu\n\nLoad Text File\n\n    Now supports outputting a dictionary named after the file, or custom input.\n\n    The dictionary contains a list of all lines in the file.\n\nLoad Batch Images\n\n    Increment images in a folder, or fetch a single image out of a batch.\n\n    Will reset it's place if the path, or pattern is changed.\n\n    pattern is a glob that allows you to do things like **/* to get all files in the directory and subdirectory or things like *.jpg to select only JPEG images in the directory specified.\n\nLatent Noise Injection: Inject latent noise into a latent image\n\nLatent Size to Number: Latent sizes in tensor width/height\n\nLatent Upscale by Factor: Upscale a latent image by a facto\n\nMiDaS Depth Approximation: Produce a depth approximation of a single image input\n\nMiDaS Mask Image: Mask a input image using MiDaS with a desired color\n\nNumber Operation\n\nNumber to Seed\n\nNumber to Float\n\nNumber to Int\n\nNumber to String\n\nNumber to Text\n\nRandom Number\n\nSave Text File: Save a text string to a file\n\nSeed: Return a seed\n\nTensor Batch to Image: Select a single image out of a latent batch for post processing with filters\n\nText Add Tokens: Add custom tokens to parse in filenames or other text.\n\nText Add Token by Input: Add custom token by inputs representing single single line name and value of the token\n\nText Concatenate: Merge two strings\n\nText Dictionary Update: Merge two dictionaries\n\nText File History: Show previously opened text files (requires restart to show last sessions files at this time)\n\nText Find and Replace: Find and replace a substring in a string\n\nText Find and Replace by Dictionary: Replace substrings in a ASCII text input with a dictionary.\n\n    The dictionary keys are used as the key to replace, and the list of lines it contains chosen at random based on the seed.\n\nText Multiline: Write a multiline text string\n\nText Parse A1111 Embeddings: Convert embeddings filenames in your prompts to embedding:[filename]] format based on your /ComfyUI/models/embeddings/ files.\n\nText Parse Noodle Soup Prompts: Parse NSP in a text input\n\nText Parse Tokens: Parse custom tokens in text.\n\nText Random Line: Select a random line from a text input string\n\nText String: Write a single line text string value\n\nText to Conditioning: Convert a text string to conditioning.\n</code></pre> <p>Text Tokens</p> <p>Text tokens can be used in the Save Text File and Save Image nodes. You can also add your own custom tokens with the Text Add Tokens node.</p> <p>The token name can be anything excluding the : character to define your token. It can also be simple Regular Expressions. Built-in Tokens</p> <pre><code>[time]\n\n    The current system microtime\n\n[time(format_code)]\n\n    The current system time in human readable format. Utilizing datetime formatting\n\n    Example: [hostname]_[time]__[time(%Y-%m-%d__%I-%M%p)] would output: SKYNET-MASTER_1680897261__2023-04-07__07-54PM\n\n[hostname]\n\n    The hostname of the system executing ComfyUI\n\n[user]\n\n    The user that is executing ComfyUI\n</code></pre> <p>Other Features Import AUTOMATIC1111 WebUI Styles</p> <p>When using the latest builds of WAS Node Suite a was_suite_config.json file will be generated (if it doesn't exist). In this file you can setup a A1111 styles import.</p> <pre><code>Run ComfyUI to generate the new /custom-nodes/was-node-suite-comfyui/was_Suite_config.json file.\n\nOpen the was_suite_config.json file with a text editor.\n\nReplace the webui_styles value from None to the path of your A1111 styles file called styles.csv. Be sure to use double backslashes for Windows paths.\n\n    Example C:\\\\python\\\\stable-diffusion-webui\\\\styles.csv\n\nRestart ComfyUI\n\nSelect a style with the Prompt Styles Node.\n\n    The first ASCII output is your positive prompt, and the second ASCII output is your negative prompt.\n</code></pre> <p>You can set webui_styles_persistent_update to true to update the WAS Node Suite styles from WebUI every start of ComfyUI Recommended Installation:</p> <p>If you're running on Linux, or non-admin account on windows you'll want to ensure /ComfyUI/custom_nodes, was-node-suite-comfyui, and WAS_Node_Suite.py has write permissions.</p> <pre><code>Navigate to your /ComfyUI/custom_nodes/ folder\n\ngit clone https://github.com/WASasquatch/was-node-suite-comfyui/\n\nStart ComfyUI\n\n    WAS Suite should uninstall legacy nodes automatically for you.\n\n    Tools will be located in the WAS Suite menu.\n</code></pre> <p>Alternate Installation:</p> <p>If you're running on Linux, or non-admin account on windows you'll want to ensure /ComfyUI/custom_nodes, and WAS_Node_Suite.py has write permissions.</p> <pre><code>Download WAS_Node_Suite.py\n\nMove the file to your /ComfyUI/custom_nodes/ folder\n\nStart, or Restart ComfyUI\n\n    WAS Suite should uninstall legacy nodes automatically for you.\n\n    Tools will be located in the WAS Suite menu.\n</code></pre> <p>Installing on Colab</p> <p>Create a new cell and add the following code, then run the cell. You may need to edit the path to your custom_nodes folder.</p> <pre><code>!git clone https://github.com/WASasquatch/was-node-suite-comfyui /content/ComfyUI/custom_nodes/was-node-suite-comfyui\n\nRestart Colab Runtime (don't disconnect)\n\n    Tools will be located in the WAS Suite menu.\n</code></pre> <p>Dependencies:</p> <p>WAS Node Suite is designed to download dependencies on it's own as needed, but what it depends on can be installed manually before use to prevent any script issues. The dependencies which are not required by ComfyUI are as follows:</p> <pre><code>BLIP\n\n    Requires transformers==4.26.1\n\n        You can try to manually install from your /python_embeds/ folder run .\\python.exe -m pip install --user --upgrade --force-reinstall transformers==4.26.1\n\nopencv\n\nscipy\n\npilgram\n\ntimm (for MiDaS and BLIP)\n\n    MiDaS Models (they will download automatically upon use and be stored in /ComfyUI/models/midas/checkpoints/, additional files may be installed by PyTorch Hub)\n\nimg2texture (for Image Seamless Texture node)\n\npythonperlin\n\n    Used for the perlin noise. I tried writing three different perlin noise functions but I couldn't get things as fast as this library, even with numpy, and that was really hard to figure out. Haha. I'm just terrible with math. Feel free to PR a in-house version so long as it doesn't take longer than a few seconds. Fastest I got was nearly a minute... Lol\n\nPythonGit\n\n    For downloading repos (such as BLIP)\n</code></pre> <p>Github Repository: https://github.com/WASasquatch/was-node-suite-comfyui</p> <p>https://civitai.com/user/WAS</p>"},{"location":"nodes/assemble_tags_node/","title":"assemble_tags_node","text":""},{"location":"nodes/assemble_tags_node/#comfyui-comfy_assemble_tags_node","title":"comfyui comfy_assemble_tags_node","text":"<ul> <li>web: https://civitai.com/models/49851/comfyui-comfyassembletagsnode</li> <li>repo: https://github.com/laojingwei/comfy_assemble_tags_node</li> </ul> <p>comfy_assemble_tags_node</p> <p>2023 04-26 Troubleshooting Instructions:</p> <p>I am very sorry that I overwrote the code of search path display and selected path display when I packaged yesterday. I just found out today that I have uploaded the code to github and civitail again. If you have downloaded it before and want to use the function of path display, Please download the latest code to overwrite this file ComfyUI\\custom_nodes\\comfy_assemble_tags_node, then go to ComfyUI\\web\\extensions\\select_tags and delete select_tags folder. If you have modified or added your content to tags.xlsx in this folder, please back up and restart ComfyUI</p> <p>It took me over a week to write. Please give me a star if you like, or give me a star on github</p> <p>gitHub: https://github.com/laojingwei/comfy_assemble_tags_node</p> <p>Gratitude model\uff1ahttps://civitai.com/models/10415/3-guofeng3</p> <p>description</p> <p>comfy_assemble_tags_node is a keyword selection and assembly modification plugin that can help you quickly generate various ai keywords.</p> <p>It has the following characteristics:</p> <ol> <li> <p>It covers most of the keywords used in ai, and makes a lot of classifications, including some common presuppositions, etc.</p> </li> <li> <p>Keywords are marked in Chinese, which is convenient for users who do not speak English to choose.</p> </li> </ol> <p>3, provides the search function, can quickly locate the approximate location of keywords, search the current page can also be global search, save time and energy.</p> <p>4, with the function of choosing memory, you can see the keywords you selected last time and the path on the home page, convenient modification and adjustment.</p> <p>5, can be customized to increase keywords, to meet different needs and preferences.</p> <p>6, you can view the current generated random seeds, easy to copy and share.</p> <p>7, can split the assembly of keywords, if the keywords are more recommended to use the assembly node, can let you want to modify the follow-up keyword can be faster to locate the keyword position to modify.</p> <p>Download method</p> <p>git</p> <p>git clone https://github.com/laojingwei/comfy_assemble_tags_node.git</p> <p>zip</p> <p>ZIP</p> <p>Installation mode</p> <ol> <li>Put the downloaded plug-in folder into this folder ComfyUI_windows_portable\\ComfyUI\\custom_nodes 2. Restart comfyui software and open the UI interface</li> </ol> <p>Node introduction</p> <p>Show Seed Displays random seeds that are currently generated</p> <p>Select Tags Tags Used to select keywords</p> <p>Assemble Tags (more keywords and often modify is recommended)</p> <p>Show Tags You can check the keywords selected by the previous nodes, which can be adjusted in more detail here (if the process does not monitor the change after adjusting the keywords, you can disconnect the chain connected with the front and click to generate)</p> <p>Usage method</p> <ol> <li> <p>Double-click the left button to search Select Tags, Assemble Tags, Show Tags and Show Seed to add nodes</p> </li> <li> <p>Right-click Add Node-&amp;gt. xww-&gt; tags-&gt; ... Select the node you want to add</p> </li> </ol> <p>Select Tags:</p> <ol> <li>You can enter the corresponding tab to find the keywords you need, or you can use search to search. If * is added in front of the search, it means to check the contents of all tabs, and the corresponding path will be displayed on the found value. If you do not add * Indicates that only the content of the current tab is searched, regardless of the global or the current tab, as long as the corresponding value is found, the text in the search box will be converted to green, and it will be white if it cannot be found, and the upper right corner of the corresponding keyword option will be displayed An arrow animation will appear to tell you what you are searching for. 2. Click OK to display the English in reverse. The content in the reverse display here cannot be changed just to show you what you have selected. 3. You can tag the content in it by yourself. Modify or add in the xlsx table 4. The input box on the right side of the option is weight input 5. For more detailed operations, please see the screenshot below</li> </ol> <p>Assemble Tags:</p> <p>1, can be used with Select Tags, can also be used alone, when used with Select Tags, please right-click in the bottom to find which option you want to change to take the input content, then you can Select Tags connected to the option 2, the options are preset, available without</p> <p>Show Tags:</p> <ol> <li>Keywords can be fine-tuned with Select Tags or Assemble Tags, or can be used alone</li> </ol> <p>Show Seed:</p> <ol> <li>It can be connected to VAE Decode, there are as many KSampler seeds as there are in the process, and you can copy corresponding seeds for use. When we generate images, we think the generated images are pretty good. If we wanted to modify the seeds a little bit, we couldn't get the generated seeds, because the seeds shown in KSampler will generate the next seeds immediately after the call. In this case, you can use this node to solve your needs</li> </ol> <p>https://civitai.com/user/xww911 This model permits users to:</p> <p>y Use the model without crediting the creator n Sell images they generate n Run on services that generate images for money y Share merges using this model n Sell this model or merges using this model y Have different permissions when sharing merges</p>"},{"location":"nodes/ctdde%20ComfyUI%20Workflows/","title":"ctdde ComfyUI Workflows","text":""},{"location":"nodes/ctdde%20ComfyUI%20Workflows/#comfyui-workflows","title":"ComfyUI Workflows","text":"<ul> <li>web https://civitai.com/models/22651/</li> <li>repo:</li> </ul>"},{"location":"nodes/ctdde%20ComfyUI%20Workflows/#installation","title":"Installation:","text":"<p>Install https://github.com/Fannovel16/comfy_controlnet_preprocessors</p> <p>thanks to Fannovel16</p> <p>Download:  https://civitai.com/models/9251/controlnet-pre-trained-models</p> <p>at least Canny, Depth is optional</p> <p>or difference model (takes your model as input, might be more accurate)</p> <p>https://civitai.com/models/9868/controlnet-pre-trained-difference-models</p> <p>put those controlnet models into ComfyUI/models/controlnet</p> <p>thanks to Ally</p> <p>Download attached file and put the nodes into ComfyUI/custom_nodes</p> <p>Included are some (but not all) nodes from</p> <p>https://civitai.com/models/20793/was-node-suites-comfyui</p> <p>thanks to WAS and abbail</p> <p>Restart ComfyUI</p> <p>Usage:</p> <p>Disconnect latent input on the output sampler at first.</p> <p>Generate your desired prompt. Adding \"open sky background\" helps avoid other objects in the scene.</p> <p>Adjust the brightness on the image filter. During my testing a value of -0.200 and lower works. Flowing hair is usually the most problematic, and poses where people lean on other objects like walls.</p> <p>A free standing pose and short straight hair works really well.</p> <p>The point of the brightness is to limit the depth map somewhat to create a mask that fits your subject.</p> <p>Choose your background image. It can either be the same latent image or a blank image created by a node, or even a loaded image.</p> <p>Alternatively you want to add another image filter between the yellow</p> <p>Monochromatic Clip and ImageToMask node and add a little bit of blur to achieve some blend between the subject and the new background.</p> <p>When you are satisfied with how the mask looks, connect the VAEEncodeForInpaint Latent output to the Ksampler (WAS) Output again and press Queue Prompt.</p> <p>For this to work you NEED the canny controlnet. I have tried HED and normalmap aswell, but canny seems to work the best.</p> <p>Depending on your subject you might need another controlnet type.</p> <p>You would have to switch the preprocessor from canny and install a different controlnet for your application.</p> <p>Applying the depth controlnet is OPTIONAL. It will add a slight 3d effect to your output depending on the strenght.</p> <p>If you are strictly working with 2D like anime or painting you can bypass the depth controlnet.</p> <p>Simply remove the condition from the depth controlnet and input it into the canny controlnet. Without the canny controlnet however, your output generation will look way different than your seed preview.</p> <p>I added alot of reroute nodes to make it more obvious of what goes where.</p> <p>Reproducing this workflow in automatic1111 does require alot of manual steps, even using 3rd party program to create the mask, so this method with comfy should be very convenient.</p> <p>Disclaimer: Some of the color of the added background will still bleed into the final image.</p> <p>BGRemoval V1: Requirements:</p> <p>https://github.com/Fannovel16/comfy_controlnet_preprocessors</p> <p>https://civitai.com/models/9251/controlnet-pre-trained-models</p> <p>(openpose and depth model)</p> <p>optional but highly suggest:</p> <p>https://civitai.com/api/download/models/25829</p> <p>Tested with a few other models aswell like F222 and protogen.</p> <p>The following explanation and instruction can also be found in a text node inside the workflow:</p> <p>I used different \"masks\" in the load addition node aswell, with vastly different results but all returned backgrounds. Also the same mask in different colors.</p> <p>This one is strickly a gradient of white created on a completely black background.</p> <p>I can only presume that the AI uses it as some sort of guidance to distribute noise.</p> <p>The green condition combine node input order actually matters. The output of the green \"Depth Strenght\" has to go into the lower input.</p> <p>The upper input of that node comes from CLIP positive with the pose.</p> <p>The blue sampler section does nothing more than to produce a depth map which is then encoded to latent and used as latent input for the cyan colored output sampler.</p> <p>For the green image scale, I would suggest to always match it with your original image size with crop DISABLED</p> <p>DEPTH STRENGHT setting can change the final image quite a bit, and you will lose weight of the original positive prompt if its too high.</p> <p>You can start as low as 0 in some cases, but if background appears you want to increase it, even up to a strenght of 1. (lower is better)</p> <p>If you haven't already I suggest you download and install</p> <p>Fannovels preprocessors found here</p> <p>https://github.com/Fannovel16/comfy_controlnet_preprocessors</p> <p>The seed node and the Sampler with seed input you can download here</p> <p>https://civitai.com/api/download/models/25829</p> <p>The openpose and depth models are found here</p> <p>https://civitai.com/models/9251/controlnet-pre-trained-models</p> <p>You could also try using WAS's depth preprocessor, but I found it to create a depth map that is too detailed, or doesn't have the threshold that is useful for this.</p> <p>The model I am using you can find here</p> <p>https://civitai.com/models/21343/rpgmix</p> <p>https://civitai.com/user/ctdde</p>"},{"location":"nodes/embeddings_compare/","title":"embeddings_compare","text":""},{"location":"nodes/embeddings_compare/#embeddings_compare-comfyui","title":"embeddings_compare ComfyUI","text":"<ul> <li>web: https://civitai.com/models/54555/embeddingscompare-comfyui</li> <li>repo: </li> </ul> <p>This is a node setup workflow to compare different textual inversion embeddings in comfyUI.</p> <p>Use Cases can be comparing of Character likeness embeddings or testing of different strengths of the same embedding.</p> <p>For testing I am using Emma Watson, Selena Gomez and Wednesday Addams textual inversions, but any other can be put in their place.</p> <p>https://civitai.com/user/CyberSnacc</p>"},{"location":"nodes/plasma%20noise%20generator/","title":"plasma noise generator","text":""},{"location":"nodes/plasma%20noise%20generator/#jordach-comfy-plasma","title":"Jordach comfy-plasma","text":"<ul> <li>web:</li> <li>repo: https://github.com/Jordach/comfy-plasma</li> </ul> <p>A simple plasma noise generator for ComfyUI. Other noise generators may appear over time.</p>"},{"location":"nodes/pythongosssss%20custom%20scripts/","title":"pythongosssss custom scripts","text":""},{"location":"nodes/pythongosssss%20custom%20scripts/#pythongossssss-scripts-and-nodes","title":"pythongossssss scripts and nodes","text":"<ul> <li>web:</li> <li>repo: https://github.com/pythongosssss/ComfyUI-Custom-Scripts</li> </ul> <p>editor's note:</p> <ul> <li>pygo's repo isn't something you drop into custom nodes. Go into each folder and get the files needed for <code>custom_nodes</code> or <code>web/extensions</code></li> <li><code>.js</code> files go in <code>web/extensions</code></li> <li><code>.py</code> files go in  <code>custom_nodes</code></li> </ul>"},{"location":"nodes/simple%20wildcard/","title":"simple wildcard","text":""},{"location":"nodes/simple%20wildcard/#simple-wildcard-for-comfyui","title":"simple wildcard for ComfyUI","text":"<ul> <li>web: https://civitai.com/models/21611/</li> <li>repo: https://github.com/lilly1987/ComfyUI_node_Lilly</li> </ul> <pre><code>\nex : {3$$a1|{b2|c3|}|d4|{-$$|f|g}|{-2$$h||i}|{1-$$j|k|}}/{$$l|m|}/{0$$n|}\n\n{1|2|3} -&gt; 1 or 2 or 3\n\n{2$$a|b|c} -&gt; a,b or b,c or c,a or bb or ....\n\n{9$$a|b|c} -&gt; {3$$a|b|c} auto fix max count\n\n{1-2$$a|b|c} -&gt; 1~2 random choise\n\n{-2$$a|b|c} -&gt; {0-2$$a|b|c} 0-2\n\n{1-$$a|b|c} -&gt; {0-3$$a|b|c} 1-max\n\n{-$$a|b|c} -&gt; {0-3$$a|b|c} 0-max\n\n{9$$ {and|or} $$a|b|c} -&gt; a or b or c / c and b and a\n\n</code></pre> <p>install : ComfyUI\\custom_nodes\\ComfyUI_node_Lilly</p> <p>txt folder :</p> <p>ComfyUI\\wildcards</p> <p>or edit line</p> <p>card_path=os.path.dirname(file)+\"\\..\\wildcards\\*\\.txt\"</p> <p>https://civitai.com/user/lilly1987</p>"},{"location":"nodes/string%20replace/","title":"string replace","text":""},{"location":"nodes/string%20replace/#string-replace_1","title":"string replace","text":"<ul> <li>web: https://gist.github.com/johnbeech</li> <li>repo: https://gist.github.com/johnbeech/69b564dc3556d5479d329076945b243c</li> </ul>"},{"location":"nodes/string%20replace/#install","title":"install","text":"<p>The file is in text format. Click on \"view\" then click on \"raw\" and save the resulting <code>.py</code> file in <code>custom_nodes</code></p>"},{"location":"nodes/theally%20ComfyUI%20Custom%20Workflows/","title":"theally ComfyUI Custom Workflows","text":""},{"location":"nodes/theally%20ComfyUI%20Custom%20Workflows/#comfyui-custom-workflows","title":"ComfyUI Custom Workflows","text":"<ul> <li>web: https://civitai.com/models/20443/</li> <li>repo: </li> </ul> <p>These files are Custom Workflows for ComfyUI</p> <p>ComfyUI is a super powerful node-based, modular, interface for Stable Diffusion. I have a brief overview of what it is and does here. And full tutorial on my Patreon, updated frequently.</p> <p>Please consider joining my Patreon! Advanced SD tutorials, settings explanations, adult-art, from a female content creator (me!) patreon.com/theally</p> <p>https://github.com/comfyanonymous/ComfyUI https://theally.notion.site/New-Interface-ComfyUI-cf09400cf86f41ff9c1143d7471d1475 https://www.patreon.com/theally http://patreon.com/theally</p> <p>https://civitai.com/user/theally</p>"},{"location":"nodes/theally%20Custom%20Nodes/","title":"theally Custom Nodes","text":""},{"location":"nodes/theally%20Custom%20Nodes/#comfyui-custom-nodes","title":"ComfyUI Custom Nodes","text":"<ul> <li>web: https://civitai.com/models/19625/</li> <li>repo: </li> </ul> <p>These files are Custom Nodes for ComfyUI</p> <p>ComfyUI is a super powerful node-based, modular, interface for Stable Diffusion. I have a brief overview of what it is and does here. And full tutorial content coming soon on my Patreon.</p> <p>In this model card I will be posting some of the custom Nodes I create. Let me know if you have any ideas, or if there's any feature you'd specifically like to see added as a Node!</p> <p>Please consider joining my Patreon! Advanced SD tutorials, settings explanations, adult-art, from a female content creator (me!) patreon.com/theally</p> <p>https://github.com/comfyanonymous/ComfyUI https://theally.notion.site/New-Interface-ComfyUI-cf09400cf86f41ff9c1143d7471d1475 https://www.patreon.com/theally http://patreon.com/theally</p> <p>https://civitai.com/user/theally n Use the model without crediting the creator n Sell images they generate n Run on services that generate images for money n Share merges using this model n Sell this model or merges using this model n Have different permissions when sharing merges</p>"},{"location":"nodes/tinyterraNodes/","title":"tinyterraNodes","text":""},{"location":"nodes/tinyterraNodes/#tinyterranodes_1","title":"tinyterraNodes","text":"<ul> <li>web:</li> <li>repo: https://github.com/TinyTerra/ComfyUI_tinyterraNodes</li> </ul> <p>A selection of custom nodes for ComfyUI.</p>"},{"location":"nodes/trNodes/","title":"trNodes","text":""},{"location":"nodes/trNodes/#trnodes_1","title":"trNodes","text":"<ul> <li>web: </li> <li>repo: https://github.com/trojblue/trNodes</li> </ul> <p>custom node modules for ComfyUI</p>"},{"location":"nodes/trNodes/#installation","title":"Installation","text":"<ol> <li>git clone this repo under ComfyUI/custom_nodes</li> <li>install dependencies:</li> </ol> <pre><code># go to project python folder\ncd python_embeded\n./python.exe -m pip install -r opencv-python scikit-image blendmodes\n</code></pre>"},{"location":"nodes/trNodes/#nodes","title":"Nodes","text":"<p>image_layering:</p> <ul> <li>Adds 1-3 layers of image on top of one another; will remove white background and use it as transparent layers</li> <li>TODO: add alpha control</li> </ul> <p>color_correction:</p> <ul> <li>Adjusts the color of the target image according to another image; ported from stable diffusion WebUI</li> </ul> <p>model_router:</p> <ul> <li>Batch reroutes model, clip, vae, condition_1 and condition_2 for cleaner workflow</li> </ul>"},{"location":"nodes/trNodes/#use","title":"Use","text":"<ul> <li>Install nodes</li> <li>open ComfyUI</li> <li>You'll find the new nodes under trNodes folder</li> </ul>"},{"location":"nodes/translation_node/","title":"translation_node","text":""},{"location":"nodes/translation_node/#comfyui-comfy_translation_node","title":"comfyui comfy_translation_node","text":"<ul> <li>web: https://civitai.com/models/42647/comfyui-comfytranslationnode</li> <li>web1: https://civitai.com/models/38309/comfyui-comfyui-comfytranslation</li> <li>repo: https://github.com/laojingwei/comfy_translation_node</li> </ul> <p>comfy_translation_node</p> <p>Updated --2023 04 24</p> <p>There is no change in the update function, only a small change has been made to adjust the grouping of nodes and put them into xww-tran. If you have downloaded them before, you do not need to update them. If you want to update them, if you use openIE.txt, please first backup openIE.txt and then update it. If you don't overwrite comfy_translation_node directly, you'll be fine</p> <p>Gratitude model\uff1ahttps://civitai.com/models/10415/3-guofeng3</p> <p>For more details, please visit\uff1ahttps://github.com/laojingwei/comfy_translation_node</p> <p>Description</p> <pre><code>can be used on ComfyUI interface node for translation, chinese-english translation, translation youdao and Google API support, a variety of options for your choice;\n\nCN2EN: Support: translation api switch, whether to open translation, Chinese-English switch, embeddings selection, embeddings weight adjustment;\n\nTweak Keywords CN2EN: You can tweak the translated content, making it more flexible to tweak your keywords\n</code></pre> <p>Download</p> <p>git clone git clone https://github.com/laojingwei/comfy_translation_node.git</p> <p>ZIP download</p> <p>Position installation and operation before use</p> <pre><code>Place the downloaded folder comfy_translation_node under ComfyUI\\custom_nodes\n\nIf you want to start ComfyUI is used when you want the browser (just want to use the default browser can skip this step), you can edit openIE. TXT (path: PATH field in ComfyUI\\custom_nodes\\comfy_translation_node\\openIE.txt), add the corresponding browser.exe execution file path to it, for example: PATH=\"C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\", other fields (*PATHOLD, SAVE*) never move, no matter what value they are do not change! If the ComfyUI code update fails, then you need to reset the other two fields to *PATHOLD=\"\"* and *SAVE=\"FALSE\"*\n\nGo back to the ComfyUI update folder ComfyUI_windows_portable\\update and execute the three files in order. Because this plugin requires the latest code ComfyUI, not update can't use, if you have is the latest (2023-04-15) have updated after you can skip this step\n\nGo to the root directory and double-click run_nvidia_gpu.bat (or run_cpu.bat) to start ComfyUI. Note that if you did step 2 above, you will need to close the ComfyUI launcher and start again, because the first startup only initialized the browser path, which cannot be read. You will need to start again to open the browser you want. In the future, as long as you do not update the ComfyUI code, you will be able to open your browser every time. If you have an update later, you need to update the code twice before the service takes effect\n</code></pre> <p>Instructions for use</p> <pre><code>Node addition method: You can find utils by double-clicking into search and output related words or right-click to find utils and click in to search. Both of these nodes can be directly connected to the Text of CLIP Text Encode. CLIP Text Encode accepts text entry, and Text entry can be right-click on CLIP Text Encode. Find the Convert text to input, select it and the text entry will appear on the left side. (This is very important because many nodes can open the text entry in this way.)\n\nCLIP Text Encode CN2EN\n</code></pre> <p>Text input field: Enter keywords</p> <p>\"language\": 'AUTO' will not be translated, the original text will be output, 'CN' will be translated into Chinese (note that due to the translation api, please ensure that it is pure English before being translated into Chinese), 'EN' will be translated into English (Chinese and English can be mixed)</p> <p>\"transAPI\": 'YOUDAO' uses Youdao api to translate,'GOOGLE' uses Google api to translate (Google call time is slow, generally about 2 seconds, sometimes will call failure, it is recommended to use Youdao translation, speed is very fast, but different translation api translated content is a little different, Which one you choose depends on your preference)</p> <p>\"log\": 'CLOSE' does not print logs on the console,'OPEN' prints logs on the console</p> <p>\"embeddings\": 'none' is not used. Other: Select the model you want (if there is no model in the embeddingsStrength folder, embeddings and EmbeddingsStrength are not displayed)</p> <p>\"embeddingsStrength\": it sets the weight,</p> <p>Tweak Keywords CN2EN</p> <pre><code>Display the input content with CLIP Text Encode CN2EN to display the translated content; Due to the limitations of the translation api, there may be some problems with the translated format, you can correct it here if necessary; If you don't think you want to translate certain words, you can edit specific words, which can make your keywords more perfect and produce better pictures If the tweak_keywords_CN2EN node cannot view content after the ComfyUI code is updated, check whether the folder tweak_keywords_CN2EN exists in the ComfyUI\\web\\extensions path first, If yes, you can decompress tweak_keywords_CN2EN.zip (path: ComfyUI\\custom_nodes\\comfy_translation_node\\ tweak_Keywords_cn2en.zip). Manually add it to ComfyUI\\web\\extensions (it is not usually overwritten, I give you a zip pack just in case)\n</code></pre> <p>https://civitai.com/user/xww911 This model permits users to:</p> <p>y Use the model without crediting the creator n Sell images they generate n Run on services that generate images for money y Share merges using this model n Sell this model or merges using this model y Have different permissions when sharing merges</p>"},{"location":"nodes/wyrdes%20ComfyUI%20Workflows/","title":"wyrdes ComfyUI Workflows","text":""},{"location":"nodes/wyrdes%20ComfyUI%20Workflows/#wyrdes-comfyui-workflows_1","title":"wyrde's ComfyUI Workflows","text":"<ul> <li>web: https://civitai.com/models/28719/wyrdes-comfyui-workflows</li> <li>repo: https://github.com/wyrde/wyrde-comfyui-workflows</li> </ul> <p>wyrde's workflows for various things</p> <p>More examples and help documents on github: https://github.com/wyrde/wyrde-comfyui-workflows</p> <p>The recent changes to civit's UI make sharing these on civit a painful process.</p> <p>Expand the About this Version box to the right \u2192 to see more.</p>"}]}